{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milestone2",
      "provenance": [],
      "collapsed_sections": [
        "7NPOKFIPnRRE",
        "lhdUe-JtsXTf",
        "bvdK-54n_O7W",
        "bmaQAG_C_kIP",
        "_VqlquQRvWb3",
        "SQJwOb0arZ-F",
        "Ya6sKz-woGu8"
      ],
      "authorship_tag": "ABX9TyPrNPB6bUn/9vIavk8K9cpN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qiopta/MADSm2/blob/main/Milestone2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LVUVMXpnF5C"
      },
      "source": [
        "# Section 1 - Getting the environment set, including colab based IDE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OscokJSEmls6"
      },
      "source": [
        "#!pip install colabcode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_CQKMEHmvsb"
      },
      "source": [
        "#from colabcode import ColabCode #not needed as uVM for IDE based bert\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "#from lime.lime_text import LimeTextExplainer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler #doesnt work on sparse matrices\n",
        "from sklearn.preprocessing import MaxAbsScaler #therefore using this\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "import re\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import ensemble\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "ZPGElO0zm0-q",
        "outputId": "0590064f-8f36-4de8-82e8-62a29e5d65cd"
      },
      "source": [
        "# !pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3660ad28-6394-4ada-9fb5-fb16361cbd77\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3660ad28-6394-4ada-9fb5-fb16361cbd77\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"qiopta\",\"key\":\"64b826e59c2b570f04f47f4020f2d923\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-yYzzJTm6gJ"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xs03KiGm93C"
      },
      "source": [
        "#ColabCode(port=10000, password = 'Qiopta', mount_drive=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NPOKFIPnRRE"
      },
      "source": [
        "# Section 2 - Notes for the IDE environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7VlCWuIoJj9"
      },
      "source": [
        "Download the UMICH data from Kaggle with:\n",
        "\n",
        "!kaggle competitions download -c umich-siads-695-predicting-text-difficulty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_yPeXzCpe4c"
      },
      "source": [
        "# Section 3 Local Colab analysis, upload datasets create train/test dfs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlzOZzftnV0F",
        "outputId": "5d227f51-e9f3-4fb1-ba83-1bc66e303749"
      },
      "source": [
        "!kaggle competitions download -c umich-siads-695-predicting-text-difficulty"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sampleSubmission.csv.zip to /content\n",
            "  0% 0.00/278k [00:00<?, ?B/s]\n",
            "100% 278k/278k [00:00<00:00, 27.7MB/s]\n",
            "Downloading AoA_51715_words.csv.zip to /content\n",
            "  0% 0.00/834k [00:00<?, ?B/s]\n",
            "100% 834k/834k [00:00<00:00, 55.2MB/s]\n",
            "Downloading WikiLarge_Train.csv.zip to /content\n",
            " 44% 9.00M/20.3M [00:01<00:01, 7.68MB/s]\n",
            "100% 20.3M/20.3M [00:01<00:00, 13.2MB/s]\n",
            "Downloading additional_resource_file_readme.txt to /content\n",
            "  0% 0.00/2.83k [00:00<?, ?B/s]\n",
            "100% 2.83k/2.83k [00:00<00:00, 2.47MB/s]\n",
            "Downloading WikiLarge_Test.csv.zip to /content\n",
            "100% 4.73M/4.73M [00:00<00:00, 11.1MB/s]\n",
            "\n",
            "Downloading Concreteness_ratings_Brysbaert_et_al_BRM.txt.zip to /content\n",
            "  0% 0.00/410k [00:00<?, ?B/s]\n",
            "100% 410k/410k [00:00<00:00, 57.1MB/s]\n",
            "Downloading dale_chall.txt to /content\n",
            "  0% 0.00/18.3k [00:00<?, ?B/s]\n",
            "100% 18.3k/18.3k [00:00<00:00, 19.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS8UkwFJpP_0",
        "outputId": "f63e5305-15b7-4644-f6c7-1e03ab2751e8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "additional_resource_file_readme.txt\t\t  sample_data\n",
            "AoA_51715_words.csv.zip\t\t\t\t  sampleSubmission.csv.zip\n",
            "Concreteness_ratings_Brysbaert_et_al_BRM.txt.zip  WikiLarge_Test.csv.zip\n",
            "dale_chall.txt\t\t\t\t\t  WikiLarge_Train.csv.zip\n",
            "kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYi-mVaopUQS"
      },
      "source": [
        "zf = zipfile.ZipFile('/content/WikiLarge_Train.csv.zip') \n",
        "train_df = pd.read_csv(zf.open('WikiLarge_Train.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVaRQFpkqrhU"
      },
      "source": [
        "zf = zipfile.ZipFile('/content/WikiLarge_Test.csv.zip') \n",
        "test_df = pd.read_csv(zf.open('WikiLarge_Test.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItbEzK60XM-A"
      },
      "source": [
        "tenK_train = train_df.sample(10000)\n",
        "onehK_train = train_df.sample(100000)\n",
        "twohK_train = train_df.sample(200000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5i4nb6e9KUq"
      },
      "source": [
        "## Vectorize the the training data, note tenK sample size baseline, labels will need to match when training classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERzIFT8kAs03",
        "outputId": "a7b6733d-d3b2-41dd-ad97-343b633ff703"
      },
      "source": [
        "%%time\n",
        "#This needs vectorizing to work\n",
        "vectorizer = TfidfVectorizer(min_df = 100, stop_words ='english', ngram_range = (1, 2)) #experiment unigrams (most defaults in this set were tested with min-df =100 and ngrams (1,2), best looks to be 25 (1,2))\n",
        "X_train    = vectorizer.fit_transform(tenK_train['original_text'])\n",
        "vec_test   = vectorizer.transform(test_df['original_text']) \n",
        "# takes 30 secs on CPU runtime for full data, 767ms for 10K, 50K took 2.5 s, trying 100K took 5.5 secs, 200K takes 10 secs. With 2 bigrams (now with test set inc takes c.5secs for 10K)\n",
        "# Get shuffle split params set up\n",
        "shuff_spt = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.07 s, sys: 34.7 ms, total: 4.1 s\n",
            "Wall time: 4.14 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhdUe-JtsXTf"
      },
      "source": [
        "#Section 4 Dummy classifier, baseline classifiers with minimal pre-processing AND GBT classifier in this section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG5XeGB7upWP"
      },
      "source": [
        "# split train into dev set(s)\n",
        "# for dummy baseline clf using CV=5 cross validation score "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfN_DfqprKts"
      },
      "source": [
        "mostf_clf = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eKc1DlcwWPs"
      },
      "source": [
        "scores = cross_val_score(mostf_clf, train_df.original_text, train_df.label, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhsodh_zw80U",
        "outputId": "1bbfc156-fc28-459c-bc5f-7749df8ad3a5"
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49999760056626635"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-dYdKqUumnD",
        "outputId": "72f1b3f9-4439-49c9-9986-5ed20957b6b4"
      },
      "source": [
        "#comparison with stratified, shuffle and loo cv\n",
        "loo = LeaveOneOut() #too time consuming for large dataset, better for smaller\n",
        "shuff_spt = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=10)\n",
        "scores = cross_val_score(mostf_clf, train_df.original_text, train_df.label, cv=shuff_spt)\n",
        "scores #showing remarkable consistency, its balanced."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.49977445, 0.49972647, 0.49914581, 0.49899704, 0.49870432,\n",
              "       0.49979365, 0.4995729 , 0.49976966, 0.49976486, 0.49848837])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZusmfJ2vw_Ih",
        "outputId": "138529d1-e205-4ddb-e89e-2bf68c034f4a"
      },
      "source": [
        "mostf_clf.fit(train_df.original_text, train_df.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(constant=None, random_state=42, strategy='most_frequent')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrATRZQJ4UdR"
      },
      "source": [
        "dclf_preds = mostf_clf.predict(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1WpTC4942fr",
        "outputId": "c73c5989-7658-4f84-ba5d-aa89d7f0d277"
      },
      "source": [
        "len(dclf_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119092"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTdkIJ3b456b",
        "outputId": "0ba39973-3df3-45cd-ee35-0b77654425e5"
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119092, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tI6ZLbC48_K",
        "outputId": "82884da1-287b-4de9-d015-09c7459357bd"
      },
      "source": [
        "dclf_preds[:50]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa_IKMZM5CAK"
      },
      "source": [
        "# Add id's to preds, write to CSV\n",
        "dclf_pred_df = pd.DataFrame(data=dclf_preds).reset_index()\n",
        "dclf_pred_df.columns = ['id', 'label']\n",
        "dclf_pred_df.to_csv('dclf_preds.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG4Uj2jJ5vq4"
      },
      "source": [
        "#files.download('dclf_preds.csv') #this worked and was accepted by Kaggle as a submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3b1rWY87giT"
      },
      "source": [
        "#testing submission via API, this worked :-)\n",
        "#!kaggle competitions submit umich-siads-695-predicting-text-difficulty -f dclf_preds.csv -m \"Testing submission via Colab API, copy of dummy CLF result\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvdK-54n_O7W"
      },
      "source": [
        "## Gradient boost decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_YUao729TuS"
      },
      "source": [
        "GBDT_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=.1, max_depth=3, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1EHa3YFXNcf"
      },
      "source": [
        "Starting with only 10000 rows for baseline model, will need to shuffle the data to ensure I get balanced labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrphyya0GCWE"
      },
      "source": [
        "#Option fit and set sample weights to sub-set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1efVuxLAaoq",
        "outputId": "f146be73-c30c-46b2-f689-4f409c3ca5f1"
      },
      "source": [
        "%%time\n",
        "scores = cross_val_score(GBDT_clf, X_train, tenK_train.label, cv=shuff_spt) # a slice of 10000 takes 3.9 secs, 100K takes 95 secs.\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.67 s, sys: 9.69 ms, total: 3.68 s\n",
            "Wall time: 3.68 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAtY6zMnANlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974c0b5a-ad93-40cc-cc21-42e418263c49"
      },
      "source": [
        "scores.mean() #suggests c.58% accuracy, will try to run on test set and make a submission, 58% on 10K, 60% on 100K could try CATboost to utilise GPU training. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5688799999999998"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWCVVRXdcwlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1849f2ec-9fa1-442d-9a42-2ec6da9b36c9"
      },
      "source": [
        "vec_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<119092x81 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 201976 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npSBU7uAbH1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a336b6d-43c7-4bf7-bc05-b322cd83697e"
      },
      "source": [
        "%%time\n",
        "GBDT_clf.fit(X_train, tenK_train.label) #took 20 secs for 100K\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 693 ms, sys: 1.99 ms, total: 695 ms\n",
            "Wall time: 701 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=42, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyszDW4Kbn6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2091772-ccec-44a1-8993-a5221f5910c3"
      },
      "source": [
        "%%time\n",
        "gb_preds = GBDT_clf.predict(vec_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 165 ms, sys: 955 µs, total: 166 ms\n",
            "Wall time: 169 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNX_LdC4buP0"
      },
      "source": [
        "# # Add id's to preds, write to CSV\n",
        "gb_clf_pred_df = pd.DataFrame(data = gb_preds).reset_index()\n",
        "gb_clf_pred_df.columns = ['id', 'label']\n",
        "gb_clf_pred_df.to_csv('gb_preds.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM_JkUBbd2at"
      },
      "source": [
        "#!kaggle competitions submit umich-siads-695-predicting-text-difficulty -f gb_preds.csv -m \"10K GBDT trained submit via Colab API, local CV gives 57%\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udwOYt-mAVuv"
      },
      "source": [
        "# Section 5 Logistic regresson classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTHb2OgNeQWs"
      },
      "source": [
        "lr_clf = LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000) #baseline hyparameters, could be worth running grid search for L2 etc. Do this on the 10K version, rather than the 100K :-)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paEQw2pEBYtY",
        "outputId": "91a83738-a769-4e16-c4e6-c06e9679c9e9"
      },
      "source": [
        "scores = cross_val_score(lr_clf, X_train, tenK_train.label, cv=shuff_spt) # 3.9 secs for 10K, very similar result, 7 secs for 100K with max iter 100 - 64%, trying max iter 1000 with 100K - still 64% but converged quickly\n",
        "scores.mean() #66.17% on 200hk, using 10K for expermiments - baseline here is 55.798 but sometimes as high as 57.68% and LR is about as good as GBDT and faster (uni/bigrams best;  bi and trigrams worse) (min df 50 looks better by c.1%, 25 is 2% better)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5686599999999999"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QioJ3knrRKlA",
        "outputId": "69126368-857a-4b0c-d517-d7681f161466"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 87)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UPwr62Cla2G",
        "outputId": "7f2b1ac4-2f5a-47af-9440-064aa4bca35d"
      },
      "source": [
        "#Function to remove brackets terms and re fit vec/clf run CV\n",
        "cleaned_tenK_train = tenK_train.replace(to_replace ='-LRB-|-RRB-', value = '', regex = True)\n",
        "X_train    = vectorizer.fit_transform(cleaned_tenK_train['original_text'])\n",
        "scores = cross_val_score(lr_clf, X_train, cleaned_tenK_train.label, cv=shuff_spt) \n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55026"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBYST37pmukb"
      },
      "source": [
        "So removing brackets might help 'interpret' clusters/topics but actually weakens the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTh2ql7dlpFy"
      },
      "source": [
        "#re-run vectorizer and scoring steps to check impact of pre-processing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "726AlXZBRTv5",
        "outputId": "5da1ca51-deda-4db4-b91b-54da9ac70c66"
      },
      "source": [
        "tenK_train.label.shape #an issue at 2000K training where X only has 1928 features and expects 3831 as above..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqKptf5fBuQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbd5b5b-1064-4d19-ae12-784a12504b26"
      },
      "source": [
        "%%time\n",
        "lr_clf.fit(X_train, tenK_train.label)\n",
        "lr_preds = lr_clf.predict(vec_test)\n",
        "lr_clf_pred_df = pd.DataFrame(data = lr_preds).reset_index()\n",
        "lr_clf_pred_df.columns = ['id', 'label']\n",
        "lr_clf_pred_df.to_csv('lr_preds.csv', index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 226 ms, sys: 4.95 ms, total: 231 ms\n",
            "Wall time: 235 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vM-QiOHC3w6"
      },
      "source": [
        "#!kaggle competitions submit umich-siads-695-predicting-text-difficulty -f lr_preds.csv -m \"100K LR trained submit via Colab API, local CV gives 64% expected to be better than vanilla GBDT result, and did not converge so could increase max iterations from default next\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmaQAG_C_kIP"
      },
      "source": [
        "# Section 6 Initial scaling and unsupervised learning experiments\n",
        "Based on LR clf using 10K vectorized examples.\n",
        "\n",
        "\n",
        "* Scaling - MaxAbs, Standard, and Robust produce very little effect on the TFIDF vectorizes sparse matrix\n",
        "* PCA\n",
        "* Alternative vectorization\n",
        "* Clustering\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHxfk6zRDJSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b602983b-eee7-40b8-e0a3-063ebdf8e53c"
      },
      "source": [
        "lr_clf = LogisticRegression(solver='lbfgs', random_state = RANDOM_SEED, max_iter=1000)  #baseline hyparameters, could be worth running grid search for L2 etc. Do this on the 10K version)\n",
        "\n",
        "scalers = [MaxAbsScaler(), StandardScaler(with_mean=False), RobustScaler(with_centering=False)]\n",
        "for scaler in scalers:\n",
        "  print ('For %scaler.' %scaler)\n",
        "  scaler.fit(X_train)\n",
        "  X_train_scaled = scaler.transform(X_train)\n",
        "  scores = cross_val_score(lr_clf, X_train_scaled, tenK_train.label, cv=shuff_spt) # \n",
        "  print (\"Mean CV Score:                       \", scores.mean()) #Essentially no difference to unscaled\n",
        "print ('The baseline unscaled LR CLF produced 0.55798')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For MaxAbsScaler(copy=True)caler.\n",
            "Mean CV Score:                        0.56474\n",
            "For StandardScaler(copy=True, with_mean=False, with_std=True)caler.\n",
            "Mean CV Score:                        0.56206\n",
            "For RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=False,\n",
            "             with_scaling=True)caler.\n",
            "Mean CV Score:                        0.5611599999999999\n",
            "The baseline unscaled LR CLF produced 0.55798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VqlquQRvWb3"
      },
      "source": [
        "## Understanding PCA\n",
        "X_train.shape # shows we have created 81 features by TFDIF Vectorizing (10,000, 81) the 'Original text' in the training data when sampling 10,000 rows.\n",
        "\n",
        "From SKlearn: In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in sklearn.feature_extraction.text. In that context, it is known as latent semantic analysis (LSA)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzNAxKv2HTBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c1f0d0-ed63-4098-9a2c-9a9b98185b6e"
      },
      "source": [
        "# # Do MaxAbsScaler first, as has best impact on accuracy\n",
        "scaler = MaxAbsScaler()\n",
        "X_scaled = scaler.fit_transform(X_train) #not required for Truncated SVD\n",
        "# Do fit/transform NOTE PCA does not support sparse input. See TruncatedSVD for a possible alternative.\n",
        "tsvd = TruncatedSVD(n_components=8, random_state= RANDOM_SEED) # going with 10% of the features created by a 10K sample vectorized \n",
        "X_tsvd = tsvd.fit_transform(X_scaled) # toggle X_train &  X_scaled in experiments\n",
        "#compare\n",
        "print (X_tsvd.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL5Z9nmCXh5u",
        "outputId": "53a1d585-d674-4ff7-e379-3a4dcdec104f"
      },
      "source": [
        "X_tsvd[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.73126677e-02,  1.62641512e-02,  4.11473296e-04,  8.91435487e-02,\n",
              "        1.71415235e-01,  4.41418705e-01, -1.19893416e-01, -5.96791277e-02])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqyE5ABGZTGs",
        "outputId": "74f6c52a-ce05-42e6-d73c-81b83bd8c92f"
      },
      "source": [
        "X_train[0] #shows 76 Features here, so sample is not commonly seeded (ie today's 10K rows arent yesterdays 10K rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x84 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9QjQxmPZW4r",
        "outputId": "fb79c08e-b60a-437d-ae2b-7cdaaa46b263"
      },
      "source": [
        "lr_clf = LogisticRegression(solver='lbfgs', random_state = RANDOM_SEED, max_iter=1000)  #baseline hyparameters, could be worth running grid search for L2 etc. Do this on the 10K version)\n",
        "scores = cross_val_score(lr_clf, X_tsvd, tenK_train.label, cv=shuff_spt) # \n",
        "print (\"Mean CV Score for T-SVD model:       \", scores.mean()) #obvs\n",
        "print ('The baseline unscaled LR CLF produced 0.55798')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean CV Score for T-SVD model:        0.54208\n",
            "The baseline unscaled LR CLF produced 0.55798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQJwOb0arZ-F"
      },
      "source": [
        "## Using K means to find clusters\n",
        "Based on 543 Assignment two.  Measure of cluster quality to find optimal K in range from 2-9.  Then run the K clusters, and discover the mean centroid (typical sentence) for each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnT-eodJaOyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2226ab-77c5-45ef-c4f9-21f42b63be28"
      },
      "source": [
        "%%time\n",
        "#find optimal K, in k means clustering\n",
        "for k in range(2,10):\n",
        "    print ('_'*25, k)\n",
        "    kmeans = KMeans(n_clusters = k, init='k-means++', max_iter=100, n_init=1, random_state=RANDOM_SEED)\n",
        "    kmeans.fit(X_train)\n",
        "    #print ('Shape of reshaped labels:', kmeans.labels_.reshape(-1,1).shape)\n",
        "    #print ('Shape of reshaped labels after .ravel():', kmeans.labels_.reshape(-1,1).ravel().shape)\n",
        "    print ('Davies Boulding   (should be low)  ', davies_bouldin_score(X_train.toarray(), kmeans.labels_.reshape(-1,1).ravel()))\n",
        "    print ('Calinski Harabasz (should be high)', calinski_harabasz_score(X_train.toarray(), kmeans.labels_.reshape(-1,1).ravel()) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________________ 2\n",
            "Davies Boulding   (should be low)   1.957223081315819\n",
            "Calinski Harabasz (should be high) 111.90020332520037\n",
            "_________________________ 3\n",
            "Davies Boulding   (should be low)   2.8078980771658215\n",
            "Calinski Harabasz (should be high) 662.5526837787584\n",
            "_________________________ 4\n",
            "Davies Boulding   (should be low)   2.606389755111424\n",
            "Calinski Harabasz (should be high) 205.9193558938128\n",
            "_________________________ 5\n",
            "Davies Boulding   (should be low)   2.4467202989922088\n",
            "Calinski Harabasz (should be high) 193.57458665440305\n",
            "_________________________ 6\n",
            "Davies Boulding   (should be low)   2.2642491445387747\n",
            "Calinski Harabasz (should be high) 204.97787233547197\n",
            "_________________________ 7\n",
            "Davies Boulding   (should be low)   2.1074865768187925\n",
            "Calinski Harabasz (should be high) 401.94181190043093\n",
            "_________________________ 8\n",
            "Davies Boulding   (should be low)   1.6884034160012935\n",
            "Calinski Harabasz (should be high) 406.0670699557539\n",
            "_________________________ 9\n",
            "Davies Boulding   (should be low)   1.6492486031161049\n",
            "Calinski Harabasz (should be high) 390.5964864877278\n",
            "CPU times: user 2.6 s, sys: 775 ms, total: 3.37 s\n",
            "Wall time: 2.54 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwofe1OwtUwa"
      },
      "source": [
        "# Start with 2 clusters for intelligbility of results\n",
        "# Going to go with K=7 based on above\n",
        "def kmeans_sentences(k, X):\n",
        "    ''' Input k, number of clusters and training data\n",
        "    returns k lists, each of which are the ten most highly weighted words in\n",
        "    mean centriod of cluster'''\n",
        "    \n",
        "    #Specify and get model\n",
        "    kmeans = KMeans(n_clusters = k, init='k-means++', max_iter=100, n_init=1, random_state= RANDOM_SEED)\n",
        "    kmeans.fit(X)\n",
        "    \n",
        "    #find typical vector for each cluster (gets K X row shape)\n",
        "    centers = kmeans.cluster_centers_\n",
        "    \n",
        "    #get f names\n",
        "    f_names = vectorizer.get_feature_names()\n",
        "    \n",
        "    #compile k lists of strs within a dict, str for final terms, lst to iterate over and get terms using IDX's\n",
        "    d = {}\n",
        "    for i in range(k):\n",
        "        d[\"cl\" + str(i) + '_str'] = [] #empty list to capture list of strings\n",
        "        cent_idx_s = centers.argsort()[i][-1:-6:-1] #gets Kth item and slices last six items (based on mean sent length analysis)\n",
        "        d[\"cl\" + str(i) + '_lst'] = list(cent_idx_s)  #previously was slice [i][10] first 10 items from cent idx variable change per iteration\n",
        "    \n",
        "    #get feature names for idxed items and compile list of lists as result\n",
        "    result = []\n",
        "    \n",
        "    for i in range(k):\n",
        "        for item  in d[\"cl\" + str(i) + '_lst']:\n",
        "            d[\"cl\" + str(i) + '_str'].append(f_names[item])\n",
        "        result.append(d[\"cl\" + str(i) + '_str']) \n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFdf4L13zz2o"
      },
      "source": [
        "list_centroids = kmeans_sentences(7, X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuiDIgUqz7un",
        "outputId": "d96f9bc0-f0f8-481b-f035-437531c49b8c"
      },
      "source": [
        "print ([list for list in list_centroids])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['called', 'lrb', 'rrb', 'used', 'area'], ['south', 'west', 'east', 'north', 'located'], ['born', 'lrb born', 'rrb', 'lrb', 'football'], ['city', 'france', 'used', 'department', 'commune'], ['state', 'city', 'states', 'county', 'university'], ['people', 'lrb', 'rrb', 'commune', 'region'], ['rrb', 'lrb', 'lrb rrb', 'known', 'used']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkjcYGD735K2"
      },
      "source": [
        "Need to ascertain average sentence length in X_train, as ten words in the centroid list may be too big"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3cE4JT74CyO",
        "outputId": "255dfe2d-cdd2-4651-b980-ad096af171b7"
      },
      "source": [
        "len(tenK_train.iloc[0,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbzNtSRZBsH8"
      },
      "source": [
        "tenK_train['word_count'] = tenK_train.original_text.apply(lambda x: len(str(x).split(' ')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Lmb56_1E0BS3",
        "outputId": "0c6aed22-4b6d-4880-e957-a47770ed3a95"
      },
      "source": [
        "tenK_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>408219</th>\n",
              "      <td>Wolfgang Kleff -LRB- born 16 November , 1946 -...</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392848</th>\n",
              "      <td>Tungsten -LRB- sometimes named wolfram -RRB- i...</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188804</th>\n",
              "      <td>The headwaters are located on Mount Timpanogos...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140847</th>\n",
              "      <td>Saint-Sauveur-de-Puynormand is a commune in th...</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192959</th>\n",
              "      <td>Whether on land or in water , fire salamanders...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original_text  label  word_count\n",
              "408219  Wolfgang Kleff -LRB- born 16 November , 1946 -...      0          16\n",
              "392848  Tungsten -LRB- sometimes named wolfram -RRB- i...      0          25\n",
              "188804  The headwaters are located on Mount Timpanogos...      1          17\n",
              "140847  Saint-Sauveur-de-Puynormand is a commune in th...      1          14\n",
              "192959  Whether on land or in water , fire salamanders...      1          12"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHucdjTL1f3d",
        "outputId": "03ec3674-5404-4331-c23f-4cc96c678639"
      },
      "source": [
        "#sanity check split\n",
        "sample_sent = tenK_train.iloc[2,0]\n",
        "print (sample_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The headwaters are located on Mount Timpanogos and the river continues down through American Fork Canyon .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "Ln0iP6XTCgrr",
        "outputId": "2ea30766-5f15-4104-97e1-6844f894fa95"
      },
      "source": [
        "tenK_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>10000.00000</td>\n",
              "      <td>10000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.50230</td>\n",
              "      <td>21.735600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.50002</td>\n",
              "      <td>12.499677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>13.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>29.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>80.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             label    word_count\n",
              "count  10000.00000  10000.000000\n",
              "mean       0.50230     21.735600\n",
              "std        0.50002     12.499677\n",
              "min        0.00000      1.000000\n",
              "25%        0.00000     13.000000\n",
              "50%        1.00000     20.000000\n",
              "75%        1.00000     29.000000\n",
              "max        1.00000     80.000000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prxbv-jaCpO5"
      },
      "source": [
        "#given mean sentence lengh of 22, 10 chars is about half the sentance, so going for 5 as smaller size. Edit function above "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HBuisglE2VMi",
        "outputId": "bf79c6ed-eb11-4801-a15b-3fefc145c623"
      },
      "source": [
        "sample_sent[-1:-6:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'. noy'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDwdXEA42ps5"
      },
      "source": [
        "# it seems that the brackets are messing up the purity of the clusters so removing them may give more distinctive cluster, but will it improve classifiers?...\n",
        "# 7 Clusters with 5 top features looks to be about right, need to lose the RRB / LRB notation. So next step is some preprocessing....\n",
        "# if the clustering above is post vectorizer, then need to re-do the sample, remove the unwanted terms RRB - LRB and any seperators, revectorise and repeat."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FPJCXubFb0E"
      },
      "source": [
        "#new sample 10K\n",
        "new_10K_train  = train_df.sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "PKo3h_XoFsAF",
        "outputId": "93982a65-47c2-42b2-84c9-a5f747111bd0"
      },
      "source": [
        "new_10K_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147920</th>\n",
              "      <td>The U.S. Census Bureau 2007 estimate for the c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141327</th>\n",
              "      <td>It was named in honor of Spencer Compton , the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205320</th>\n",
              "      <td>RSS -LRB- most commonly translated as '' Reall...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408639</th>\n",
              "      <td>Wayland is connected with Wayland 's Smithy , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237174</th>\n",
              "      <td>At the end of the level , the player is awarde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            original_text  label\n",
              "147920  The U.S. Census Bureau 2007 estimate for the c...      1\n",
              "141327  It was named in honor of Spencer Compton , the...      1\n",
              "205320  RSS -LRB- most commonly translated as '' Reall...      1\n",
              "408639  Wayland is connected with Wayland 's Smithy , ...      0\n",
              "237174  At the end of the level , the player is awarde...      0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSpZSsaXFu90"
      },
      "source": [
        "brb_sent = new_10K_train.iloc[9,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk2LfbHSGG18",
        "outputId": "204ac524-6c82-47a6-d10c-76eab0ba02de"
      },
      "source": [
        "re.findall(r'-LRB-|-RRB-', brb_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-LRB-', '-RRB-']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDHhfubNPRhS",
        "outputId": "71aadd63-2a10-4f04-e7df-b9b0e5264e9e"
      },
      "source": [
        "re.search('(-LRB-|-RRB-)', brb_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(5, 10), match='-LRB-'>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO_t-Z2qP1gz"
      },
      "source": [
        "regex_pattern = re.compile(r'-LRB-|-RRB-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm-tfR4JNFOj"
      },
      "source": [
        "#Function to remove these terms\n",
        "cleaned_new_10K = new_10K_train.replace(to_replace ='-LRB-|-RRB-', value = '', regex = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFhdlC0SQ7SZ",
        "outputId": "c3bcbff9-187b-4397-c4b5-450d2d893983"
      },
      "source": [
        "print (cleaned_new_10K.iloc[9,0])\n",
        "print (brb_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dill  Anethum graveolens  is a short-lived perennial herb .\n",
            "Dill -LRB- Anethum graveolens -RRB- is a short-lived perennial herb .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05gNStwxpaDK"
      },
      "source": [
        "# Worth inserting a step here that looks into different params for the Vectorizor and seeing how this impacts the quality of the clusters."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eeG9HGCRC5Q"
      },
      "source": [
        "cleanANDvec10K = vectorizer.fit_transform(cleaned_new_10K['original_text']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1MLt_uqRw55"
      },
      "source": [
        "list_centroids = kmeans_sentences(7, cleanANDvec10K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVMIjx_kR354",
        "outputId": "ecc62462-a746-4e26-db04-092ed4613376"
      },
      "source": [
        "print ([list for list in list_centroids])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['united', 'states', 'united states', 'city', 'county'], ['born', 'football', 'player', 'football player', 'american'], ['march', 'born', 'known', 'american', 'december'], ['known', 'city', 'called', 'new', 'time'], ['used', 'like', 'time', 'known', 'english'], ['france', 'department', 'commune', 'region', 'north'], ['world', 'war', 'known', 'june', 'including']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0SQu9jaR8aQ",
        "outputId": "5affe218-70be-46aa-9dda-47f829a56395"
      },
      "source": [
        "## Comparison to 10K sample with Brackets\n",
        "lr_clf = LogisticRegression(solver='lbfgs', random_state = RANDOM_SEED, max_iter=1000)  #exact copy of baseline hyparameters on the 10K version)\n",
        "\n",
        "scalers = [MaxAbsScaler(), StandardScaler(with_mean=False), RobustScaler(with_centering=False)]\n",
        "for scaler in scalers:\n",
        "  print ('For: ', scaler)\n",
        "  scaler.fit(cleanANDvec10K)\n",
        "  X_train_scaled = scaler.transform(cleanANDvec10K)\n",
        "  scores = cross_val_score(lr_clf, X_train_scaled, new_10K_train.label, cv=shuff_spt) # \n",
        "  print (\"Mean CV Score:                       \", scores.mean()) #Essentially no difference to unscaled\n",
        "print ('The baseline unscaled LR CLF produced 0.55798')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For:  MaxAbsScaler(copy=True)\n",
            "Mean CV Score:                        0.5599000000000001\n",
            "For:  StandardScaler(copy=True, with_mean=False, with_std=True)\n",
            "Mean CV Score:                        0.5569400000000001\n",
            "For:  RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=False,\n",
            "             with_scaling=True)\n",
            "Mean CV Score:                        0.5559000000000001\n",
            "The baseline unscaled LR CLF produced 0.55798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aneLi1JwTitv"
      },
      "source": [
        "## Exploring impact of Vectorizor parameters on quality of clusters, with cleaned data sample\n",
        "##vectorizer = TfidfVectorizer(min_df = 100, stop_words ='english', ngram_range = (1, 2)) #Baseline params used to here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQtyUNrmr39",
        "outputId": "d0c83dfa-d751-4a2c-e7b3-4e6875afa697"
      },
      "source": [
        "#Using grid search CV and LR classfier - outcome measure is Davies_Boulding index score\n",
        "\n",
        "kmeans = KMeans(n_clusters = 9, init='k-means++', max_iter=100, n_init=1, random_state=RANDOM_SEED)\n",
        "kmeans.fit(cleanANDvec10K)\n",
        "    #print ('Shape of reshaped labels:', kmeans.labels_.reshape(-1,1).shape)\n",
        "    #print ('Shape of reshaped labels after .ravel():', kmeans.labels_.reshape(-1,1).ravel().shape)\n",
        "print ('Davies Boulding   (should be low)  ', davies_bouldin_score(cleanANDvec10K.toarray(), kmeans.labels_.reshape(-1,1).ravel()))\n",
        "print ('Davies Boulding   (should be low)   1.581827421894325 - BASELINE with k=9 and X_train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Davies Boulding   (should be low)   1.9899423568884462\n",
            "Davies Boulding   (should be low)   1.581827421894325 - BASELINE with k=9 and X_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OphrbsF60s0D"
      },
      "source": [
        "The above shows a reduction in DB idx from 1.58 to 1.32 where k=9 and with the cleaned (RRB removed) data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shLeOnpJt2oy"
      },
      "source": [
        "#gridsearch CV on Vectorizer\n",
        "pipeline = Pipeline([\n",
        "           ('vect', TfidfVectorizer()),\n",
        "           ('km', KMeans(n_clusters = 9, init='k-means++', max_iter=100, n_init=1, random_state=RANDOM_SEED)),\n",
        "           \n",
        "])\n",
        "\n",
        "parameters = {\n",
        "    'vect__min_df': [20, 50, 100, 250, 500], \n",
        "    'vect__ngram_range':[(1,1), (1,2), (2,2), (1,3),(2,3),(3,3)]\n",
        "    }\n",
        "\n",
        "gridsearch  = GridSearchCV(\n",
        "    pipeline, \n",
        "    parameters, \n",
        "    #scoring=davies_bouldin_score(X, y),\n",
        "    verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dOmXm0i8x50"
      },
      "source": [
        "#Grid search not working, so create function and loop through params\n",
        "\n",
        "def fit_clusters_Qscores(X, k=9):\n",
        "  ''' \n",
        "  Input X - tfidf vectorized training data, k=number of clusters default to 9\n",
        "  Output dbscore\n",
        "  '''\n",
        "  kmeans = KMeans(n_clusters = k, init='k-means++', max_iter=100, n_init=1, random_state=RANDOM_SEED)\n",
        "  kmeans.fit(X)\n",
        "  return davies_bouldin_score(X.toarray(), kmeans.labels_.reshape(-1,1).ravel()), calinski_harabasz_score(X.toarray(), kmeans.labels_.reshape(-1,1).ravel())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA_NFawEUDrD",
        "outputId": "b95946f0-e8f6-46d7-d914-24e87e9a31a0"
      },
      "source": [
        "fit_clusters_Qscores(cleanANDvec10K)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.9899423568884462, 275.1242330936048)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U-pvgUIULZf",
        "outputId": "17e79a5c-3595-45b0-ee69-fc34b4cd7b73"
      },
      "source": [
        "for k in range(2,15):\n",
        "  result = fit_clusters_Qscores(cleanANDvec10K, k)\n",
        "  print (k, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 (1.5664841056326853, 331.3830518479815)\n",
            "3 (1.6508433479172808, 276.24187775913674)\n",
            "4 (2.3375214536318945, 223.34017449013854)\n",
            "5 (2.1240686442590415, 265.302567052471)\n",
            "6 (2.0203448175849164, 323.6203650123538)\n",
            "7 (1.8305717628879974, 316.5953381763397)\n",
            "8 (1.7529067366982627, 292.96695830750974)\n",
            "9 (1.9899423568884462, 275.1242330936048)\n",
            "10 (1.9210300092105232, 264.56561721204173)\n",
            "11 (1.8833373252871277, 252.17834275462639)\n",
            "12 (1.9216090163625488, 254.8835567110233)\n",
            "13 (1.888015475058149, 250.59051045953956)\n",
            "14 (1.8629936724488823, 263.52874762934505)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "lzwK8xBDUe4n",
        "outputId": "c416ef79-8ecb-4393-8c5d-73c0db146b1b"
      },
      "source": [
        "\n",
        "for doc_f in [20, 50, 75, 100]:\n",
        "  print (doc_f, '#'*25)\n",
        "  for idx, ngrams in enumerate([(1,1), (1,2), (2,2), (1,3),(2,3),(3,3)]):\n",
        "    vectorizer = TfidfVectorizer(min_df = doc_f, stop_words ='english', ngram_range = (ngrams[0], ngrams[1]))\n",
        "    X = vectorizer.fit_transform(cleaned_new_10K['original_text']) \n",
        "    result = fit_clusters_Qscores(X, 2)\n",
        "    print (ngrams[0], ngrams [1], result)\n",
        "# Super interesting as we climb the ngram range to trigrams less and less min-df is appropriate, however based on min_df 20 and ngrams (3,3) the db score and ch scores are superb!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20 #########################\n",
            "1 1 (4.489578276745416, 78.98152461893613)\n",
            "1 2 (2.9903142671366125, 93.59634953619782)\n",
            "2 2 (0.4829094936915861, 1989.7407525233823)\n",
            "1 3 (3.0566892688613283, 90.69406605970559)\n",
            "2 3 (0.8100272401770878, 241.30513145271829)\n",
            "3 3 (0.0481448282127027, 811.2326246232177)\n",
            "50 #########################\n",
            "1 1 (2.47867446189316, 148.47018179607602)\n",
            "1 2 (2.1807230144223526, 170.1137574538912)\n",
            "2 2 (0.10969767319188299, 5753.768345101683)\n",
            "1 3 (5.876891321826757, 126.0945150997147)\n",
            "2 3 (0.10965217359414943, 5753.520535442385)\n",
            "3 3 (0.654183748075948, 18673.492929140077)\n",
            "75 #########################\n",
            "1 1 (3.484099530582081, 262.2994262616778)\n",
            "1 2 (3.469040422743216, 268.4562787097896)\n",
            "2 2 (0.025158762144370125, 21381.658851534165)\n",
            "1 3 (3.469040422743216, 268.4562787097896)\n",
            "2 3 (0.025158762144370125, 21381.658851534165)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-cf0316acfa09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_new_10K\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_clusters_Qscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         \"\"\"\n\u001b[1;32m   1858\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                                                        \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                                        max_features)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_limit_features\u001b[0;34m(self, X, vocabulary, high, low, limit)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0mkept_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m             raise ValueError(\"After pruning, no terms remain. Try a lower\"\n\u001b[0m\u001b[1;32m   1110\u001b[0m                              \" min_df or a higher max_df.\")\n\u001b[1;32m   1111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkept_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremoved_terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: After pruning, no terms remain. Try a lower min_df or a higher max_df."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBAfUxPwxZ6A"
      },
      "source": [
        "So this ran out of runway with (3,3) ngrams and min_df of 75.  But (2,2) and 75 had VERY good results... therefore looking at this in more detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P3XQki6Xv__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1757b7-24d5-4068-f3f4-71716315b200"
      },
      "source": [
        "#input, good params as V\n",
        "def investigate_cluster_features(min_df=75, ngrams=(1,1), k=2):\n",
        "  vectorizer = TfidfVectorizer(min_df = min_df, stop_words ='english', ngram_range = ngrams)\n",
        "  X = vectorizer.fit_transform(cleaned_new_10K['original_text'])\n",
        "  list_centroids = kmeans_sentences(k, X)\n",
        "  return [list for list in list_centroids]\n",
        "investigate_cluster_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['united states', 'football player'], ['football player', 'united states']]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b6pQKBrkTCo"
      },
      "source": [
        "This turned out to be an error, higher ngrams do not help either make topics distinct nor improve supervised task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya6sKz-woGu8"
      },
      "source": [
        "# Section 7 more LSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhhGmQlRzhmo"
      },
      "source": [
        "#Following some of: https://towardsdatascience.com/latent-semantic-analysis-sentiment-classification-with-python-5f657346f6a3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl33hg86xL0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f32e728-8a90-4e9c-f473-fcb45eadf74c"
      },
      "source": [
        "X_train.shape #product of tfidf sparse matrix with 79 features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 79)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgY_x_j81_MO",
        "outputId": "4f103426-beca-4d77-8cc3-ebb5a25df36d"
      },
      "source": [
        "\n",
        "tenK_train.shape #pre-vectorization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JZZqE72N2gVl",
        "outputId": "14bc13dd-8e6e-498f-c1a5-f799f46e1a63"
      },
      "source": [
        "tenK_train.iloc[0,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'After discovering that the Bane , creators of a soft drink called Bubble Shock !'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTBgqpjU2upM",
        "outputId": "0f6f7291-62cb-4001-e291-55eaa313880d"
      },
      "source": [
        "vectorizer.vocabulary_['called'] #.vocab is key val dict. So 11 is val for key 'called'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw683JMo3nXv",
        "outputId": "2752bfcc-d85e-43b5-9842-5d683e0300c3"
      },
      "source": [
        "X_train[0, 11]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82BalWSV5bN-",
        "outputId": "39c8385e-85e0-4f8c-b1bb-3279fb6b3d5d"
      },
      "source": [
        "X_train[0].toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2sG9F-D5wCc",
        "outputId": "dd5adb75-80c4-4ab4-dd95-23e8b382bbe8"
      },
      "source": [
        "vectorizer.idf_[:11] #gives the 'scores of the first 11 terms in the dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.53761153, 5.38212663, 5.41464982, 4.73397682, 5.53761153,\n",
              "       5.36625328, 5.59531985, 5.53761153, 5.48305255, 4.08794756,\n",
              "       5.47424192])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "v29VQ_2m9U10",
        "outputId": "3d594500-0e95-4204-d68a-6847413482b0"
      },
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(12,8))\n",
        "y = tenK_train.label # my add\n",
        "chi2score = chi2(X_train, y)[0] # from the repo, adjusted for my local var name (the slice [0] is Chi2, [1] is p-val)\n",
        "\n",
        "scores = list(zip(vectorizer.get_feature_names(), chi2score))\n",
        "chi2 = sorted(scores, key=lambda x:x[1])\n",
        "topchi2 = list(zip(*chi2[-20:]))\n",
        "x = range(len(topchi2[1]))\n",
        "labels = topchi2[0]\n",
        "plt.barh(x,topchi2[1], align='center', alpha=0.5)\n",
        "plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
        "plt.yticks(x, labels)\n",
        "plt.xlabel('$\\chi^2$')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR_Wj4Iu-JE9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoVei8s9jvkj"
      },
      "source": [
        "# Section 8 Hyperparameter tuning\n",
        "- Starting with our baseline LR classifier, and the 10K sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w320IoGJpfG"
      },
      "source": [
        "X = X_train\n",
        "y = tenK_train.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUyUyBA3kAxO",
        "outputId": "7d61d8bf-bdc8-4e26-a0ed-eace3746ba38"
      },
      "source": [
        "# #more imports to move to top of sheet\n",
        "# from sklearn import ensemble\n",
        "# from sklearn import metrics\n",
        "# from sklearn import model_selection\n",
        "\n",
        "#baseline clf lr_clf = LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000) - gives 56.6222\n",
        "\n",
        "classifier = ensemble.RandomForestClassifier(n_jobs=-1, random_state=RANDOM_SEED)\n",
        "param_grid = {\n",
        "    \"n_estimators\": np.arange(100,1500, 100),  #[100,200,300,400], #for grid search\n",
        "    \"max_depth\": np.arange(1,20),              #[1,3,5,7], # for grid search\n",
        "    \"criterion\": ['gini', 'entropy'],\n",
        "    }\n",
        "\n",
        "# Grid search, took c.2.4 mins and best result was .575 criterion=entropy, max_depth=7, n_estimators=300, score=0.575, second best: criterion=gini, max_depth=7, n_estimators=200, score=0.574,\n",
        "model = model_selection.RandomizedSearchCV(\n",
        "    estimator = classifier,\n",
        "    #param_grid = param_grid, #for grid search\n",
        "    param_distributions = param_grid, # for randomizedsearchCV\n",
        "    n_iter=10, # iterations for randomized\n",
        "    scoring = 'accuracy',\n",
        "    verbose = 10,\n",
        "    n_jobs=1,\n",
        "    cv=5,\n",
        "    )\n",
        "\n",
        "model.fit(X,y)\n",
        "\n",
        "print (model.best_score_, model.best_estimator_.get_params) \n",
        "#This was for the Grid search.\n",
        "# 0.5667 <bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                      #  criterion='gini', max_depth=7, max_features='auto',\n",
        "                      #  max_leaf_nodes=None, max_samples=None,\n",
        "                      #  min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      #  min_samples_leaf=1, min_samples_split=2,\n",
        "                      #  min_weight_fraction_leaf=0.0, n_estimators=400,\n",
        "                      #  n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
        "                      #  warm_start=False)>\n",
        "# Random search took same time and got better results\n",
        "# n_estimators=700, max_depth=18, criterion=gini, score=0.580,\n",
        "# 0.5704 <bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                      #  criterion='gini', max_depth=18, max_features='auto',\n",
        "                      #  max_leaf_nodes=None, max_samples=None,\n",
        "                      #  min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                      #  min_samples_leaf=1, min_samples_split=2,\n",
        "                      #  min_weight_fraction_leaf=0.0, n_estimators=700,\n",
        "                      #  n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
        "                      #  warm_start=False)>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] n_estimators=1400, max_depth=19, criterion=gini .................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=19, criterion=gini, score=0.568, total=   9.8s\n",
            "[CV] n_estimators=1400, max_depth=19, criterion=gini .................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.8s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=19, criterion=gini, score=0.581, total=   8.5s\n",
            "[CV] n_estimators=1400, max_depth=19, criterion=gini .................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   18.3s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=19, criterion=gini, score=0.581, total=   8.5s\n",
            "[CV] n_estimators=1400, max_depth=19, criterion=gini .................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.8s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=19, criterion=gini, score=0.577, total=   8.5s\n",
            "[CV] n_estimators=1400, max_depth=19, criterion=gini .................\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   35.3s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=19, criterion=gini, score=0.568, total=   8.6s\n",
            "[CV] n_estimators=1400, max_depth=4, criterion=entropy ...............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   43.9s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=4, criterion=entropy, score=0.560, total=   5.0s\n",
            "[CV] n_estimators=1400, max_depth=4, criterion=entropy ...............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   48.9s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=4, criterion=entropy, score=0.576, total=   5.0s\n",
            "[CV] n_estimators=1400, max_depth=4, criterion=entropy ...............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   54.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=4, criterion=entropy, score=0.574, total=   5.0s\n",
            "[CV] n_estimators=1400, max_depth=4, criterion=entropy ...............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   59.0s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=4, criterion=entropy, score=0.574, total=   5.0s\n",
            "[CV] n_estimators=1400, max_depth=4, criterion=entropy ...............\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  n_estimators=1400, max_depth=4, criterion=entropy, score=0.558, total=   5.0s\n",
            "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.572, total=   4.9s\n",
            "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.582, total=   4.8s\n",
            "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.574, total=   4.8s\n",
            "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.579, total=   4.8s\n",
            "[CV] n_estimators=900, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=900, max_depth=13, criterion=entropy, score=0.567, total=   4.7s\n",
            "[CV] n_estimators=1400, max_depth=18, criterion=gini .................\n",
            "[CV]  n_estimators=1400, max_depth=18, criterion=gini, score=0.568, total=   8.2s\n",
            "[CV] n_estimators=1400, max_depth=18, criterion=gini .................\n",
            "[CV]  n_estimators=1400, max_depth=18, criterion=gini, score=0.580, total=   8.1s\n",
            "[CV] n_estimators=1400, max_depth=18, criterion=gini .................\n",
            "[CV]  n_estimators=1400, max_depth=18, criterion=gini, score=0.578, total=   8.1s\n",
            "[CV] n_estimators=1400, max_depth=18, criterion=gini .................\n",
            "[CV]  n_estimators=1400, max_depth=18, criterion=gini, score=0.577, total=   8.2s\n",
            "[CV] n_estimators=1400, max_depth=18, criterion=gini .................\n",
            "[CV]  n_estimators=1400, max_depth=18, criterion=gini, score=0.570, total=   8.3s\n",
            "[CV] n_estimators=100, max_depth=11, criterion=entropy ...............\n",
            "[CV]  n_estimators=100, max_depth=11, criterion=entropy, score=0.570, total=   0.6s\n",
            "[CV] n_estimators=100, max_depth=11, criterion=entropy ...............\n",
            "[CV]  n_estimators=100, max_depth=11, criterion=entropy, score=0.577, total=   0.6s\n",
            "[CV] n_estimators=100, max_depth=11, criterion=entropy ...............\n",
            "[CV]  n_estimators=100, max_depth=11, criterion=entropy, score=0.572, total=   0.6s\n",
            "[CV] n_estimators=100, max_depth=11, criterion=entropy ...............\n",
            "[CV]  n_estimators=100, max_depth=11, criterion=entropy, score=0.578, total=   0.6s\n",
            "[CV] n_estimators=100, max_depth=11, criterion=entropy ...............\n",
            "[CV]  n_estimators=100, max_depth=11, criterion=entropy, score=0.559, total=   0.6s\n",
            "[CV] n_estimators=400, max_depth=1, criterion=entropy ................\n",
            "[CV]  n_estimators=400, max_depth=1, criterion=entropy, score=0.541, total=   1.4s\n",
            "[CV] n_estimators=400, max_depth=1, criterion=entropy ................\n",
            "[CV]  n_estimators=400, max_depth=1, criterion=entropy, score=0.568, total=   1.4s\n",
            "[CV] n_estimators=400, max_depth=1, criterion=entropy ................\n",
            "[CV]  n_estimators=400, max_depth=1, criterion=entropy, score=0.561, total=   1.4s\n",
            "[CV] n_estimators=400, max_depth=1, criterion=entropy ................\n",
            "[CV]  n_estimators=400, max_depth=1, criterion=entropy, score=0.559, total=   1.3s\n",
            "[CV] n_estimators=400, max_depth=1, criterion=entropy ................\n",
            "[CV]  n_estimators=400, max_depth=1, criterion=entropy, score=0.547, total=   1.4s\n",
            "[CV] n_estimators=1300, max_depth=9, criterion=gini ..................\n",
            "[CV]  n_estimators=1300, max_depth=9, criterion=gini, score=0.571, total=   5.4s\n",
            "[CV] n_estimators=1300, max_depth=9, criterion=gini ..................\n",
            "[CV]  n_estimators=1300, max_depth=9, criterion=gini, score=0.582, total=   5.2s\n",
            "[CV] n_estimators=1300, max_depth=9, criterion=gini ..................\n",
            "[CV]  n_estimators=1300, max_depth=9, criterion=gini, score=0.578, total=   5.3s\n",
            "[CV] n_estimators=1300, max_depth=9, criterion=gini ..................\n",
            "[CV]  n_estimators=1300, max_depth=9, criterion=gini, score=0.576, total=   5.3s\n",
            "[CV] n_estimators=1300, max_depth=9, criterion=gini ..................\n",
            "[CV]  n_estimators=1300, max_depth=9, criterion=gini, score=0.568, total=   5.3s\n",
            "[CV] n_estimators=1200, max_depth=19, criterion=gini .................\n",
            "[CV]  n_estimators=1200, max_depth=19, criterion=gini, score=0.567, total=   7.3s\n",
            "[CV] n_estimators=1200, max_depth=19, criterion=gini .................\n",
            "[CV]  n_estimators=1200, max_depth=19, criterion=gini, score=0.580, total=   7.2s\n",
            "[CV] n_estimators=1200, max_depth=19, criterion=gini .................\n",
            "[CV]  n_estimators=1200, max_depth=19, criterion=gini, score=0.581, total=   7.3s\n",
            "[CV] n_estimators=1200, max_depth=19, criterion=gini .................\n",
            "[CV]  n_estimators=1200, max_depth=19, criterion=gini, score=0.578, total=   7.3s\n",
            "[CV] n_estimators=1200, max_depth=19, criterion=gini .................\n",
            "[CV]  n_estimators=1200, max_depth=19, criterion=gini, score=0.570, total=   7.3s\n",
            "[CV] n_estimators=700, max_depth=3, criterion=entropy ................\n",
            "[CV]  n_estimators=700, max_depth=3, criterion=entropy, score=0.554, total=   2.4s\n",
            "[CV] n_estimators=700, max_depth=3, criterion=entropy ................\n",
            "[CV]  n_estimators=700, max_depth=3, criterion=entropy, score=0.571, total=   2.4s\n",
            "[CV] n_estimators=700, max_depth=3, criterion=entropy ................\n",
            "[CV]  n_estimators=700, max_depth=3, criterion=entropy, score=0.567, total=   2.3s\n",
            "[CV] n_estimators=700, max_depth=3, criterion=entropy ................\n",
            "[CV]  n_estimators=700, max_depth=3, criterion=entropy, score=0.576, total=   2.3s\n",
            "[CV] n_estimators=700, max_depth=3, criterion=entropy ................\n",
            "[CV]  n_estimators=700, max_depth=3, criterion=entropy, score=0.556, total=   2.3s\n",
            "[CV] n_estimators=200, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=200, max_depth=13, criterion=entropy, score=0.569, total=   1.2s\n",
            "[CV] n_estimators=200, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=200, max_depth=13, criterion=entropy, score=0.582, total=   1.1s\n",
            "[CV] n_estimators=200, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=200, max_depth=13, criterion=entropy, score=0.574, total=   1.1s\n",
            "[CV] n_estimators=200, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=200, max_depth=13, criterion=entropy, score=0.579, total=   1.1s\n",
            "[CV] n_estimators=200, max_depth=13, criterion=entropy ...............\n",
            "[CV]  n_estimators=200, max_depth=13, criterion=entropy, score=0.559, total=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5748 <bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=9, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=1300,\n",
            "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4KG7NSU4BoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c913902b-e930-4634-debf-b4beb8f93e78"
      },
      "source": [
        "#baseline clf lr_clf = LogisticRegression(solver='lbfgs', random_state=42, max_iter=1000) - gives 56.866\n",
        "\n",
        "classifier = LogisticRegression(n_jobs=-1, random_state=RANDOM_SEED)\n",
        "param_grid = {\n",
        "    \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    \"C\":np.logspace(-3,3,20),\n",
        "    \"penalty\":[\"l1\",\"l2\",\"elasticnet\"],  \n",
        "    }\n",
        "\n",
        "model = model_selection.RandomizedSearchCV(\n",
        "    estimator = classifier,\n",
        "    #param_grid = param_grid, #for grid search\n",
        "    param_distributions = param_grid, # for randomizedsearchCV\n",
        "    n_iter=10, # iterations for randomized\n",
        "    scoring = 'accuracy',\n",
        "    verbose = 10,\n",
        "    n_jobs=1,\n",
        "    cv=5,\n",
        "    )\n",
        "\n",
        "model.fit(X,y)\n",
        "\n",
        "print (model.best_score_, model.best_estimator_.get_params) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[CV] solver=newton-cg, penalty=elasticnet, C=0.018329807108324356 ....\n",
            "[CV]  solver=newton-cg, penalty=elasticnet, C=0.018329807108324356, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=elasticnet, C=0.018329807108324356 ....\n",
            "[CV]  solver=newton-cg, penalty=elasticnet, C=0.018329807108324356, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=elasticnet, C=0.018329807108324356 ....\n",
            "[CV]  solver=newton-cg, penalty=elasticnet, C=0.018329807108324356, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=elasticnet, C=0.018329807108324356 ....\n",
            "[CV]  solver=newton-cg, penalty=elasticnet, C=0.018329807108324356, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=elasticnet, C=0.018329807108324356 ....\n",
            "[CV]  solver=newton-cg, penalty=elasticnet, C=0.018329807108324356, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=0.07847599703514611 .............\n",
            "[CV]  solver=liblinear, penalty=l2, C=0.07847599703514611, score=0.561, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=0.07847599703514611 .............\n",
            "[CV]  solver=liblinear, penalty=l2, C=0.07847599703514611, score=0.587, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=0.07847599703514611 .............\n",
            "[CV]  solver=liblinear, penalty=l2, C=0.07847599703514611, score=0.574, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=0.07847599703514611 .............\n",
            "[CV]  solver=liblinear, penalty=l2, C=0.07847599703514611, score=0.566, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=0.07847599703514611 .............\n",
            "[CV]  solver=liblinear, penalty=l2, C=0.07847599703514611, score=0.565, total=   0.0s\n",
            "[CV] solver=lbfgs, penalty=l1, C=0.008858667904100823 ................\n",
            "[CV]  solver=lbfgs, penalty=l1, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=lbfgs, penalty=l1, C=0.008858667904100823 ................\n",
            "[CV]  solver=lbfgs, penalty=l1, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=lbfgs, penalty=l1, C=0.008858667904100823 ................\n",
            "[CV]  solver=lbfgs, penalty=l1, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=lbfgs, penalty=l1, C=0.008858667904100823 ................\n",
            "[CV]  solver=lbfgs, penalty=l1, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=lbfgs, penalty=l1, C=0.008858667904100823 ................\n",
            "[CV]  solver=lbfgs, penalty=l1, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=0.004281332398719396 .........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=0.004281332398719396, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=0.004281332398719396 .........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=0.004281332398719396, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=0.004281332398719396 .........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=0.004281332398719396, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=0.004281332398719396 .........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=0.004281332398719396, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=0.004281332398719396 .........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=0.004281332398719396, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=elasticnet, C=0.008858667904100823 ....\n",
            "[CV]  solver=liblinear, penalty=elasticnet, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=elasticnet, C=0.008858667904100823 ....\n",
            "[CV]  solver=liblinear, penalty=elasticnet, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=elasticnet, C=0.008858667904100823 ....\n",
            "[CV]  solver=liblinear, penalty=elasticnet, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=elasticnet, C=0.008858667904100823 ....\n",
            "[CV]  solver=liblinear, penalty=elasticnet, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=elasticnet, C=0.008858667904100823 ....\n",
            "[CV]  solver=liblinear, penalty=elasticnet, C=0.008858667904100823, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=12.742749857031322 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=12.742749857031322, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=12.742749857031322 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=12.742749857031322, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=12.742749857031322 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=12.742749857031322, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=12.742749857031322 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=12.742749857031322, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=12.742749857031322 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=12.742749857031322, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=l1, C=0.6951927961775606 ..............\n",
            "[CV]  solver=newton-cg, penalty=l1, C=0.6951927961775606, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=l1, C=0.6951927961775606 ..............\n",
            "[CV]  solver=newton-cg, penalty=l1, C=0.6951927961775606, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=l1, C=0.6951927961775606 ..............\n",
            "[CV]  solver=newton-cg, penalty=l1, C=0.6951927961775606, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=l1, C=0.6951927961775606 ..............\n",
            "[CV]  solver=newton-cg, penalty=l1, C=0.6951927961775606, score=nan, total=   0.0s\n",
            "[CV] solver=newton-cg, penalty=l1, C=0.6951927961775606 ..............\n",
            "[CV]  solver=newton-cg, penalty=l1, C=0.6951927961775606, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=112.88378916846884 ...........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=112.88378916846884, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=112.88378916846884 ...........\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV]  solver=saga, penalty=elasticnet, C=112.88378916846884, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=112.88378916846884 ...........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=112.88378916846884, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=112.88378916846884 ...........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=112.88378916846884, score=nan, total=   0.0s\n",
            "[CV] solver=saga, penalty=elasticnet, C=112.88378916846884 ...........\n",
            "[CV]  solver=saga, penalty=elasticnet, C=112.88378916846884, score=nan, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=54.555947811685144 ..............\n",
            "[CV]  solver=liblinear, penalty=l2, C=54.555947811685144, score=0.563, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=54.555947811685144 ..............\n",
            "[CV]  solver=liblinear, penalty=l2, C=54.555947811685144, score=0.586, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=54.555947811685144 ..............\n",
            "[CV]  solver=liblinear, penalty=l2, C=54.555947811685144, score=0.576, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=54.555947811685144 ..............\n",
            "[CV]  solver=liblinear, penalty=l2, C=54.555947811685144, score=0.568, total=   0.0s\n",
            "[CV] solver=liblinear, penalty=l2, C=54.555947811685144 ..............\n",
            "[CV]  solver=liblinear, penalty=l2, C=54.555947811685144, score=0.566, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=54.555947811685144 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=54.555947811685144, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=54.555947811685144 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=54.555947811685144, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=54.555947811685144 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=54.555947811685144, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=54.555947811685144 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=54.555947811685144, score=nan, total=   0.0s\n",
            "[CV] solver=sag, penalty=l1, C=54.555947811685144 ....................\n",
            "[CV]  solver=sag, penalty=l1, C=54.555947811685144, score=nan, total=   0.0s\n",
            "0.5717 <bound method BaseEstimator.get_params of LogisticRegression(C=54.555947811685144, class_weight=None, dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=-1, penalty='l2',\n",
            "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9WiQrBOJYFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}